{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch básico 2: montando e treinando um modelo\n",
    "\n",
    "Saindo de exemplos de regressão e indo para classificação vamos olhar agora para um dataset que tenta trazer o problema de veículos autônomos para um ambiente mais simples.\n",
    "\n",
    "##  Classificação de imagens\n",
    "\n",
    "\n",
    "Temos um pequeno robô andando numa pista feita de papel. O robô tem uma câmera frontal possibilitando que ele veja para onde ele está indo. Assim, dada uma imagem ele precisa saber que ação ele vai tomar: $\\uparrow, \\leftarrow, \\rightarrow$. Queremos que o robô aprenda a andar na pista sozinho. \n",
    "\n",
    "Nós podemos tentar resolver esse problema como um problema de **aprendizado supervisionado** temos um dataset $(\\mathbf{x}_{1}, y_{1}), \\dots ,(\\mathbf{x}_{N}, y_{N})$ onde $\\mathbf{x}_i \\in \\mathbb{R}^{45\\times 80 \\times 3}$ é uma imagem e $y_i \\in \\{ \\uparrow, \\leftarrow, \\rightarrow \\}$ é um rótulo. Assim o problema de direção autônoma se resume em aprender uma função $f$ que associa para cada imagem uma distribuição de probabilidade sobre os rótulos.\n",
    "\n",
    "<table>\n",
    "<tr>\n",
    "<td>\n",
    "<img align=\"middle\"   width='600' heith='100' src='images/image_classification.png'>\n",
    "</td>\n",
    "</tr>\n",
    "</table>\n",
    "\n",
    "Mais informações sobre esse problema você pode encontrar [aqui](https://medium.com/@project_m/self-drives-me-crazy-from-0-to-self-driving-car-in-150-hours-bf4f68d50d8a).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# notebook feito para a versão 0.4.0 do Pytorch \n",
    "\n",
    "import os\n",
    "import subprocess\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from plots import plot9images, plot_confusion_matrix, plot_histogram_from_labels\n",
    "from util import randomize_in_place\n",
    "% matplotlib inline\n",
    "print(\"PyTorch version = {} \".format(torch.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Em primeiro lugar vamos ter que pegar os dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Essa célula pode demorar de acordo com sua conexão de internet.\n",
    "# Olhe o terminal para mais informações sobre o download\n",
    "if not os.path.exists(\"self_driving_pi_car_data\"):\n",
    "    pro = subprocess.Popen([\"bash\", \"download.sh\"])\n",
    "    pro.wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nesse notebook vamos usar apenas um pedaço dos dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_X = np.load(\"self_driving_pi_car_data/train_data.npy\")\n",
    "raw_y = np.load(\"self_driving_pi_car_data/train_labels.npy\")\n",
    "randomize_in_place(raw_X, raw_y)\n",
    "valid_X = raw_X[0:1000]\n",
    "valid_y = raw_y[0:1000]\n",
    "test_X = raw_X[1000:2000]\n",
    "test_y = raw_y[1000:2000]\n",
    "train_X = raw_X[2000:]\n",
    "train_y = raw_y[2000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "command2int = {\"forward\": 0, \"left\": 1, \"right\": 2}\n",
    "int2command = {i[1]: i[0] for i in command2int.items()}\n",
    "\n",
    "print(\"Informações sobre os dados\\n\")\n",
    "print(\"- Número de dados de treinamento = {}\\n\".format(train_X.shape[0]))\n",
    "print(\"- Número de dados de validação = {}\\n\".format(valid_X.shape[0]))\n",
    "print(\"- Número de dados de teste = {}\\n\".format(test_X.shape[0]))\n",
    "print(\"- Número de features = {}\\n\".format(test_X.shape[1]))\n",
    "print(\"- Número de classes = {}\\n\".format(3))\n",
    "print(\"- Legenda das classes:  (0 = forward, 1 = left, 2 = right)\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Olhando o dataset\n",
    "\n",
    "Esses dados foram coletados fazendo com que o robô desse voltas nessa pista:\n",
    "\n",
    "<table>\n",
    "<tr>\n",
    "<td>\n",
    "<img align=\"middle\" width='600' heith='100' src='images/train_track.png'>\n",
    "</td>\n",
    "</tr>\n",
    "</table>\n",
    "\n",
    "A cada ação tomada o robô tirava uma foto 45x80x3 (altura, largura, número de canais) e associava a ação tomada a essa foto.\n",
    "\n",
    "As observações $\\mathbf{x}_{1}, \\dots, \\mathbf{x}_{N}$ são as imagens transformadas em vetores (pegamos a matrix $45\\times80\\times3$ e a achatamos num vetor de tamanho $10800 = 45^*80^*3$). Cada feature aqui é a intensidade de um pixel da imagem (variando de 0 a 255).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos olhar alguns exemplos: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img9 = train_X[0:9]\n",
    "labels9 = train_y[0:9]\n",
    "labels9 = [int2command[i] for i in labels9]\n",
    "img9 = img9.reshape((9, 45, 80, 3)) \n",
    "img9 = img9[...,::-1]\n",
    "plot9images(img9, labels9, (45, 80, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Também podemos olhar como estão as distribuição das classes nos diferentes conjuntos de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_legend = [\"forward\", \"left\", \"right\"]\n",
    "plot_histogram_from_labels(train_y, labels_legend, \"train data\")\n",
    "plot_histogram_from_labels(valid_y, labels_legend, \"valid data\")\n",
    "plot_histogram_from_labels(test_y, labels_legend, \"test data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Organizando o código"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Em primeiro lugar vamos criar uma classe para guardar todos os hiper parâmetros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LRConfig(object):\n",
    "    \"\"\"\n",
    "    Holds logistic regression model hyperparams.\n",
    "    \n",
    "    :param height: image height\n",
    "    :type heights: int\n",
    "    :param width: image width\n",
    "    :type width: int\n",
    "    :param channels: image channels\n",
    "    :type channels: int\n",
    "    :param batch_size: batch size for training\n",
    "    :type batch_size: int\n",
    "    :param epochs: number of epochs\n",
    "    :type epochs: int\n",
    "    :param save_step: when step % save_step == 0, the model\n",
    "                      parameters are saved.\n",
    "    :type save_step: int\n",
    "    :param learning_rate: learning rate for the optimizer\n",
    "    :type learning_rate: float\n",
    "    :param momentum: momentum param\n",
    "    :type momentum: float\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 height=45,\n",
    "                 width=80,\n",
    "                 channels=3,\n",
    "                 classes=3,\n",
    "                 batch_size=32,\n",
    "                 epochs=3,\n",
    "                 save_step=100,\n",
    "                 learning_rate=0.01,\n",
    "                 momentum=0.1):\n",
    "        self.height = height\n",
    "        self.width = width\n",
    "        self.classes = classes\n",
    "        self.channels = channels\n",
    "        self.batch_size = batch_size\n",
    "        self.epochs = epochs\n",
    "        self.save_step = save_step\n",
    "        self.learning_rate = learning_rate\n",
    "        self.momentum = momentum\n",
    "        \n",
    "\n",
    "    def __str__(self):\n",
    "        \"\"\"\n",
    "        Get all attributs values.\n",
    "        :return: all hyperparams as a string\n",
    "        :rtype: str\n",
    "        \"\"\"\n",
    "        status = \"height = {}\\n\".format(self.height)\n",
    "        status += \"width = {}\\n\".format(self.width)\n",
    "        status += \"channels = {}\\n\".format(self.channels)\n",
    "        status += \"classes = {}\\n\".format(self.classes)\n",
    "        status += \"batch_size = {}\\n\".format(self.batch_size)\n",
    "        status += \"epochs = {}\\n\".format(self.epochs)\n",
    "        status += \"save_step = {}\\n\".format(self.save_step)\n",
    "        status += \"learning_rate = {}\\n\".format(self.learning_rate)\n",
    "        status += \"momentum = {}\\n\".format(self.momentum)\n",
    "        return status\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_config = LRConfig()\n",
    "print(\"Os hiper parâmetros do modelo de regressão logística são:\\n\")\n",
    "print(lr_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos transformar as imagens em tensores e vamos usar a classe `TensorDataset` para guardar os dados.\n",
    "\n",
    "Ao contrário do enunciado original, que copia os tensores para ter tanto a versão com bytes como a versão com floats, aqui eu apenas fico com as coisas que já foram lidas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "train_dataset = TensorDataset(torch.from_numpy(train_X),\n",
    "                              torch.from_numpy(train_y))\n",
    "valid_dataset = TensorDataset(torch.from_numpy(valid_X),\n",
    "                              torch.from_numpy(valid_y))\n",
    "test_dataset = TensorDataset(torch.from_numpy(test_X),\n",
    "                             torch.from_numpy(test_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para amostrar os dados vamos usar a classe `DataLoader` e vamos definir a classe `DataHolderGentle` para exclusivamente lidar com os dados.\n",
    "\n",
    "A classe `GentleLoader` é apenas um wrapper em cima da classe `DataLoader` garantindo que os tensores só sejam convertidos para float (o que o torna 4 vezes maior) e para long (o que o torna 8 vezes maior) quando estes forem ser utilizados pelo modelo.\n",
    "\n",
    "Se trata, então, de uma troca, que preserva memória mas talvez deixe o treinamento mais devagar, pois pra cada vez que se acessa um batch será necessário transformar os tipos dos tensores.\n",
    "\n",
    "Caso você não tenha problema de memória, você pode importar a clase `DataHolder` do arquivo DataHolder.py."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "class GentleLoader:\n",
    "    def __init__(self, dataset, batch_size, shuffle):\n",
    "        self.dataLoader = DataLoader(dataset=dataset,\n",
    "                                     batch_size=batch_size,\n",
    "                                     shuffle=True)\n",
    "    def __iter__(self):\n",
    "        return ((batch_X.type(torch.float), batch_y.type(torch.long))\n",
    "                 for (batch_X, batch_y) in self.dataLoader)\n",
    "\n",
    "\n",
    "class DataHolderGentle():\n",
    "    \"\"\"\n",
    "    Class to store all data using the GentleLoader.\n",
    "\n",
    "    :param config: hyper params configuration\n",
    "    :type config: LRConfig or DFNConfig\n",
    "    :param train_dataset: dataset of training data\n",
    "    :type train_dataset: torch.utils.data.dataset.TensorDataset\n",
    "    :param test_dataset: dataset of test data\n",
    "    :type test_dataset: torch.utils.data.dataset.TensorDataset\n",
    "    :param valid_dataset: dataset of valid data\n",
    "    :type valid_dataset: torch.utils.data.dataset.TensorDataset\n",
    "    :param batch_size: batch size for training\n",
    "    :type test_batch: batch size for the testing data\n",
    "    :param test_batch: int\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 config,\n",
    "                 train_dataset,\n",
    "                 valid_dataset,\n",
    "                 test_dataset,\n",
    "                 test_batch=1000):\n",
    "        batch_size = config.batch_size\n",
    "        self.train_loader = GentleLoader(dataset=train_dataset,\n",
    "                                         batch_size=batch_size,\n",
    "                                         shuffle=True)\n",
    "        self.valid_loader = GentleLoader(dataset=valid_dataset,\n",
    "                                         batch_size=batch_size,\n",
    "                                         shuffle=True)\n",
    "        self.test_loader = GentleLoader(dataset=test_dataset,\n",
    "                                        batch_size=test_batch,\n",
    "                                        shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Os diferentes dados de treinamento, teste e validação do nosso problema de carro autônomo vão ficar todos agrupados no objeto `self_driving_data`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self_driving_data = DataHolderGentle(lr_config, train_dataset, valid_dataset, test_dataset) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note que ao trabalharmos com imagens, nos dividimos um vetor de imagens por 255 para que o intervalo das features fique entre 0 e 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_X, batch_y = next(iter(self_driving_data.train_loader))\n",
    "batch_X = batch_X / 255\n",
    "print(\"exemplo de batch de treinamento\\n\")\n",
    "print(\"batch_X\")\n",
    "print(batch_X)\n",
    "print()\n",
    "print(\"batch_X.type =\", batch_X.type())\n",
    "print()\n",
    "print(\"batch_X.shape =\", batch_X.shape)\n",
    "print()\n",
    "print(\"\\nbatch_y\")\n",
    "print(batch_y)\n",
    "print()\n",
    "print(\"batch_y.type =\", batch_y.type())\n",
    "print()\n",
    "print(\"batch_y.shape =\", batch_y.shape)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Definindo um modelo 1: regressão logística\n",
    "\n",
    "Um modo conveniente de se definir modelos em PyTorch é feito usando a classe [`torch.nn.Module`](https://pytorch.org/docs/master/_modules/torch/nn/modules/module.html#Module). Nessa classe temos que definir apenas as operações na inicialização da classe e como o modelo vai realizar o *forward pass*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  **Exercício 4)**\n",
    "\n",
    "Podemos definir um modelo de regressão logística do seguinte modo:\n",
    "\n",
    "<table>\n",
    "<tr>\n",
    "<td>\n",
    "<img align=\"middle\"  width='600' heith='100' src='images/logistic_regression.png'>\n",
    "</td>\n",
    "</tr>\n",
    "</table>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Complete a classe `LogisticRegression`.\n",
    "\n",
    "Você deve definir a inicialização dessa classe e completar os métodos `forward` e `predict`. Note que:\n",
    "\n",
    " - o método `forward` deve retornar apenas os *logits*.\n",
    " \n",
    " - o método `predict` deve retornar $\\mathbf{\\hat{y}}$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression(nn.Module):\n",
    "    \"\"\"\n",
    "    Logistic regression model.\n",
    "    \n",
    "    You may find nn.Linear and nn.Softmax useful here.\n",
    "    \n",
    "    :param config: hyper params configuration\n",
    "    :type config: LRConfig\n",
    "    \"\"\"\n",
    "    def __init__(self, config):\n",
    "        super(LogisticRegression, self).__init__()\n",
    "        # YOUR CODE HERE:\n",
    "        raise NotImplementedError(\"falta completar o método __init__ da classe LogisticRegression\")\n",
    "        # END YOUR CODE\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Computes forward pass\n",
    "\n",
    "        :param x: input tensor\n",
    "        :type x: torch.FloatTensor(shape=(batch_size, number_of_features))\n",
    "        :return: logits\n",
    "        :rtype: torch.FloatTensor(shape=[batch_size, number_of_classes])\n",
    "        \"\"\"\n",
    "        # YOUR CODE HERE:\n",
    "        raise NotImplementedError(\"falta completar o método forward da classe LogisticRegression\")\n",
    "        # END YOUR CODE\n",
    "        return logits\n",
    "    \n",
    "    \n",
    "    def predict(self, x):\n",
    "        \"\"\"\n",
    "        Computes model's prediction\n",
    "\n",
    "        :param x: input tensor\n",
    "        :type x: torch.FloatTensor(shape=(batch_size, number_of_features))\n",
    "        :return: model's predictions\n",
    "        :rtype: torch.LongTensor(shape=[batch_size])\n",
    "        \"\"\"\n",
    "        # YOUR CODE HERE:\n",
    "        raise NotImplementedError(\"falta completar o método predict da classe LogisticRegression\")          \n",
    "        # END YOUR CODE\n",
    "        return predictions        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testes do exercío 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_model = LogisticRegression(lr_config)\n",
    "images = batch_X\n",
    "out = lr_model(images)\n",
    "assert out.type() == 'torch.FloatTensor', \"problemas com o tipo da saida do método forward\"\n",
    "assert out.shape == torch.Size([lr_config.batch_size, lr_config.classes]), \"problemas com o shape da saida do método forward\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = lr_model.predict(images)\n",
    "assert prediction.type() == 'torch.LongTensor', \"problemas com o tipo da saida do método prediction\"\n",
    "assert prediction.shape == torch.Size([lr_config.batch_size]), \"problemas com o shape da saida do método prediction\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Antes do treinamento podemos visualizar a qualidade das predições do modelo com os parâmetros randomicamente inicializados usando uma [matriz de confusão](https://en.wikipedia.org/wiki/Confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img, labels = next(iter(self_driving_data.test_loader))\n",
    "\n",
    "lr_model = LogisticRegression(lr_config)\n",
    "img = img / 255\n",
    "pred = lr_model.predict(img)\n",
    "pred = pred.numpy()\n",
    "\n",
    "plot_confusion_matrix(truth=labels.numpy(),\n",
    "                      predictions=pred,\n",
    "                      save=False,\n",
    "                      path=\"logref_confusion_matrix.png\",\n",
    "                      classes=[\"forward\", \"left\", \"right\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Temos os componentes principais para performar o treinamento:\n",
    "\n",
    "- um modelo ('LogisticRegression')\n",
    "- um dataset ('self_driving_data')\n",
    "- um conjunto de hiper parâmetros ('LRConfig')\n",
    "\n",
    "Agora basta criar um *loop* de treinamento. Vamos passar por todo o dataset um certo número de vezes (chamamos de *epoch* quando passamos por todo o dataset). A cada passagem vamos: \n",
    "\n",
    "- amostrar um batch de imagens e rótulos\n",
    "- calcular a entropia cruzada entre os logits do modelo e os rótulos\n",
    "- fazer o backward pass\n",
    "- fazer a atualização dos pesos\n",
    "- de tempos em tempos (dado pelo hiper parâmetro 'LRConfig.save_step'), vamos calcular o erro para o dataset de validação e vamos salvar os parâmetros do modelo quando vemos uma melhoria "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  **Exercício 5)**\n",
    "\n",
    "Você deve completar a função `train_model_img_classification`. Há 4 partes para ser completadas. Há um comentário em cada parte indicando o que deve ser feito."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_img_classification(model,\n",
    "                                   config,\n",
    "                                   dataholder,\n",
    "                                   model_path,\n",
    "                                   verbose=True):\n",
    "    \"\"\"\n",
    "    Train a model for image classification\n",
    "\n",
    "    :param model: image classification model\n",
    "    :type model: LogisticRegression or DFN\n",
    "    :param config: image classification model\n",
    "    :type config: LogisticRegression or DFN\n",
    "    :param dataholder: data\n",
    "    :type dataholder: DataHolder or DataHolderGentle\n",
    "    :param model_path: path to save model params\n",
    "    :type model_path: str\n",
    "    :param verbose: param to control print\n",
    "    :type verbose: bool\n",
    "    \"\"\"\n",
    "    train_loader = dataholder.train_loader\n",
    "    valid_loader = dataholder.valid_loader\n",
    "\n",
    "    best_valid_loss = float(\"inf\")\n",
    "    # YOUR CODE HERE:\n",
    "    # i) define the loss criteria and the optimizer. \n",
    "    # You may find nn.CrossEntropyLoss and torch.optim.SGD useful here.\n",
    "    raise NotImplementedError(\"falta completar a função train_model_img_classification\")\n",
    "    # criterion =  \n",
    "    # optimizer =\n",
    "    # END YOUR CODE\n",
    "    \n",
    "    train_loss = []\n",
    "    valid_loss = []\n",
    "    for epoch in range(config.epochs):\n",
    "        for step, (images, labels) in enumerate(train_loader):\n",
    "            # YOUR CODE HERE:\n",
    "            # ii) You should zero the model gradients\n",
    "            # and define the loss function for the train data.\n",
    "            raise NotImplementedError(\"falta completar a função train_model_img_classification\")\n",
    "            # loss = \n",
    "            # END YOUR CODE\n",
    "            if step % config.save_step == 0:\n",
    "                # YOUR CODE HERE:\n",
    "                # iii) You should define the loss function for the valid data.\n",
    "                raise NotImplementedError(\"falta completar a função train_model_img_classification\")\n",
    "                # v_loss = \n",
    "                # END YOUR CODE\n",
    "                valid_loss.append(float(v_loss))\n",
    "                train_loss.append(float(loss))\n",
    "                if float(v_loss) < best_valid_loss:\n",
    "                    msg = \"\\ntrain_loss = {:.3f} | valid_loss = {:.3f}\".format(float(loss),float(v_loss))\n",
    "                    torch.save(model.state_dict(), model_path)\n",
    "                    best_valid_loss = float(v_loss)\n",
    "                    if verbose:\n",
    "                        print(msg, end=\"\")\n",
    "            # YOUR CODE HERE:\n",
    "            # iv) You should do the back propagation\n",
    "            # and do the optimization step.\n",
    "            raise NotImplementedError(\"falta completar a função train_model_img_classification\")            \n",
    "            # END YOUR CODE\n",
    "    if verbose:\n",
    "        x = np.arange(1, len(train_loss) + 1, 1)\n",
    "        fig, ax = plt.subplots(1, 1, figsize=(12, 5))\n",
    "        ax.plot(x, train_loss, label='train loss')\n",
    "        ax.plot(x, valid_loss, label='valid loss')\n",
    "        ax.legend()\n",
    "        plt.xlabel('step')\n",
    "        plt.ylabel('loss')\n",
    "        plt.title('Train and valid loss')\n",
    "        plt.grid(True)\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testes do exercío 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_list = []\n",
    "\n",
    "for i in range(7):\n",
    "    my_lr_config = LRConfig(epochs=1)\n",
    "    my_lr_model = LogisticRegression(my_lr_config)\n",
    "    train_model_img_classification(my_lr_model,\n",
    "                                   my_lr_config,\n",
    "                                   self_driving_data,\n",
    "                                   'logreg.pkl',\n",
    "                                   verbose=False)\n",
    "    img, labels = next(iter(self_driving_data.test_loader))\n",
    "    img = img / 255\n",
    "    pred = my_lr_model.predict(img)\n",
    "    pred = pred.numpy()\n",
    "    accuracy = np.sum(pred == labels.numpy())/ labels.shape[0]\n",
    "    accuracy_list.append(accuracy)\n",
    "    print(\"i={}, accuracy = {:.3f}\".format(i, accuracy))\n",
    "\n",
    "assert os.path.exists(\"logreg.pkl\"), \"Problemas ao salvar o modelo\"\n",
    "assert np.mean(accuracy_list) >= 0.6, \"A acurácia média tem que ser maior que 60%\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora podemos treinar o modelo de regressão logística"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_lr_config = LRConfig()\n",
    "my_lr_model = LogisticRegression(my_lr_config)\n",
    "train_model_img_classification(my_lr_model,\n",
    "                               my_lr_config,\n",
    "                               self_driving_data,\n",
    "                               'logreg.pkl',\n",
    "                               verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Olhando a matriz de confusão com o modelo treinado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img, labels = next(iter(self_driving_data.test_loader))\n",
    "\n",
    "my_lr_model = LogisticRegression(my_lr_config)\n",
    "\n",
    "# aqui carregamos os parametros treinados do modelo\n",
    "my_lr_model.load_state_dict(torch.load('logreg.pkl'))\n",
    "img = img / 255\n",
    "pred = my_lr_model.predict(img)\n",
    "pred = pred.numpy()\n",
    "\n",
    "plot_confusion_matrix(truth=labels.numpy(),\n",
    "                      predictions=pred,\n",
    "                      save=False,\n",
    "                      path=\"logref_confusion_matrix.png\",\n",
    "                      classes=[\"forward\", \"left\", \"right\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Olhando alguns exemplos de classificação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred9 = pred[0:9]\n",
    "pred9 = [int2command[i] for i in pred9] \n",
    "img9 = img[0:9].numpy()\n",
    "labels9 = labels[0:9].numpy()\n",
    "labels9 = [int2command[i] for i in labels9]\n",
    "img9 = img9.reshape((9, 45, 80, 3))\n",
    "img9 = img9[...,::-1]\n",
    "plot9images(img9, labels9, (45, 80, 3), pred9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Definindo um modelo 2: rede neural\n",
    "\n",
    "*Deep Feedforward Networks* (DFN) são também chamadas de *feedforward neural\n",
    "networks*, *multilayer perceptrons*, ou, em bom português, **redes neurais**.\n",
    "\n",
    "Agora vamos implementar o modelo de rede neural. Como estamos estendendo a classe `nn.module` do PyTorch, definir uma rede neural não é muito mais complexo que definir um modelo de regressão logística.\n",
    "\n",
    "Mas antes de definir o modelo, vamos construir uma classe para guardar todos os hiper parâmetros de uma rede neural."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DFNConfig(LRConfig):\n",
    "    \"\"\"\n",
    "    Holds DFN model hyperparams.\n",
    "\n",
    "    :param architecture: network dense architecture\n",
    "    :type architecture: list of int\n",
    "    \"\"\"\n",
    "    def __init__(self, architecture=[100, 3]):\n",
    "        super(DFNConfig, self).__init__()\n",
    "        self.architecture = architecture\n",
    "\n",
    "    def __str__(self):\n",
    "        \"\"\"\n",
    "        Get all attributs values.\n",
    "\n",
    "        :return: all hyperparams as a string\n",
    "        :rtype: str\n",
    "        \"\"\"\n",
    "        status = \"height = {}\\n\".format(self.height)\n",
    "        status += \"width = {}\\n\".format(self.width)\n",
    "        status += \"channels = {}\\n\".format(self.channels)\n",
    "        status += \"architecture = {}\\n\".format(self.architecture)\n",
    "        status += \"batch_size = {}\\n\".format(self.batch_size)\n",
    "        status += \"epochs = {}\\n\".format(self.epochs)\n",
    "        status += \"save_step = {}\\n\".format(self.save_step)\n",
    "        status += \"learning_rate = {}\\n\".format(self.learning_rate)\n",
    "        status += \"momentum = {}\\n\".format(self.momentum)\n",
    "        return status\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfn_config = DFNConfig()\n",
    "print(\"Os hiper parâmetros do modelo de rede neural são:\\n\")\n",
    "print(dfn_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercicio 6: redes neurais profundas\n",
    "\n",
    "<table>\n",
    "<tr>\n",
    "<td>\n",
    "<img align=\"middle\"  width='400' heith='100'  src='images/dfn.png'>\n",
    "</td>\n",
    "</tr>\n",
    "</table>\n",
    "\n",
    "Nesse exemplo, você vai ter que completar a classe `DFN`. \n",
    "\n",
    "Esssa classe instancia uma rede neural de acordo com o hiper parâmetro `config.architecture`. \n",
    "\n",
    "Assim, por exemplo, se `config.architecture = [200, 100, 3]`. Essa classe vai criar uma rede neural com duas camadas escondidas: uma com 200 neurônios e outra com 100 neurônios; e a camada de saída tem tamanho 3. Note que a camada de entrada deve ser criada usando `config.height`, `config.width` e `config.channels`.\n",
    "\n",
    "Para simplificar a implementação, a não linearidade deve ser causada apenas pela função [ReLU](https://en.wikipedia.org/wiki/Rectifier_(neural_networks). Então, uma rede neural vai ser definida pelas fórmulas:\n",
    "\n",
    "<table>\n",
    "<tr>\n",
    "<td>\n",
    "<img align=\"middle\"  width='350' heith='100'  src='images/dfn_description.png'>\n",
    "</td>\n",
    "</tr>\n",
    "</table>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Como no caso da regressão logística, temos que:\n",
    "\n",
    " - o método `forward` deve retornar apenas os *logits* (os valores da última camada antes da aplicação da função softmax)\n",
    " \n",
    " - o método `predict` deve retornar $\\mathbf{\\hat{y}}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DFN(nn.Module):\n",
    "    \"\"\"\n",
    "    Deep Feedforward Network.\n",
    "    \n",
    "    The method self.add_module is useful here.\n",
    "    The class nn.ReLU() is useful too.\n",
    "    \n",
    "    :param config: hyper params configuration\n",
    "    :type config: DFNConfig\n",
    "    \"\"\"\n",
    "    def __init__(self, config):\n",
    "        super(DFN, self).__init__()\n",
    "        # YOUR CODE HERE:\n",
    "        raise NotImplementedError(\"falta completar o método __init__ da classe DFN\")\n",
    "        # END YOUR CODE\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Computes forward pass\n",
    "\n",
    "        :param x: input tensor\n",
    "        :type x: torch.FloatTensor(shape=(batch_size, number_of_features))\n",
    "        :return: logits\n",
    "        :rtype: torch.FloatTensor(shape=[batch_size, number_of_classes])\n",
    "        \"\"\"\n",
    "        # YOUR CODE HERE:\n",
    "        raise NotImplementedError(\"falta completar o método forward da classe DFN\")\n",
    "        # END YOUR CODE\n",
    "        return logits\n",
    "        \n",
    "    \n",
    "    def predict(self, x):\n",
    "        \"\"\"\n",
    "        Computes model's prediction\n",
    "\n",
    "        :param x: input tensor\n",
    "        :type x: torch.FloatTensor(shape=(batch_size, number_of_features))\n",
    "        :return: model's predictions\n",
    "        :rtype: torch.LongTensor(shape=[batch_size])\n",
    "        \"\"\"\n",
    "        # YOUR CODE HERE:\n",
    "        raise NotImplementedError(\"falta completar o método predict da classe DFN\")     \n",
    "        # END YOUR CODE\n",
    "        return predictions      \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testes do exercío 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfn_config = DFNConfig()\n",
    "dfn_model = DFN(dfn_config)\n",
    "images = batch_X\n",
    "out = dfn_model(images)\n",
    "assert out.type() == 'torch.FloatTensor', \"problemas com o tipo da saida do método forward\"\n",
    "assert out.shape == torch.Size([dfn_config.batch_size, dfn_config.classes]), \"problemas com o shape da saida do método forward\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = dfn_model.predict(images)\n",
    "assert prediction.type() == 'torch.LongTensor', \"problemas com o tipo da saida do método prediction\"\n",
    "assert prediction.shape == torch.Size([dfn_config.batch_size]), \"problemas com o shape da saida do método prediction\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def param_checker(config, model):\n",
    "    \"\"\"\n",
    "    Check if the dfn model's has the right kind of parameters\n",
    "\n",
    "    :param config: model's hyperparamters \n",
    "    :type config: DFNConfig\n",
    "    :param model: neural network \n",
    "    :type model: DFN\n",
    "    \"\"\"\n",
    "    input_shape = config.height * config.width * config.channels\n",
    "    all_params = list(model.parameters())\n",
    "    msg = \"Modelo sem nenhum parâmetro\"\n",
    "    assert all_params != [], msg  \n",
    "    architecture = [input_shape] + config.architecture\n",
    "    count = 0\n",
    "    for params in all_params:\n",
    "        shape = tuple(params.shape)\n",
    "        if len(shape) == 2:\n",
    "            msgW = \"{} != torch.Size([{}, {}])\".format(params.shape, shape[0], shape[1]) \n",
    "            assert shape == (architecture[count + 1], architecture[count])  \n",
    "        else:\n",
    "            msgb = \"{} != torch.Size([{}])\".format(params.shape, shape[0]) \n",
    "            assert shape == (architecture[count + 1],)  \n",
    "            count += 1\n",
    "    print(\"Todos os parâmetros ok\")\n",
    "\n",
    "\n",
    "\n",
    "deep_config1 = DFNConfig(architecture=[400, 300, 200, 100, 50, 10])\n",
    "deep_model1 = DFN(deep_config1)\n",
    "\n",
    "\n",
    "deep_config2 = DFNConfig(architecture=[800, 600, 400, 300, 200, 100, 50, 27])\n",
    "deep_model2 = DFN(deep_config2)\n",
    "\n",
    "\n",
    "deep_config3 = DFNConfig(architecture=[900, 400, 300, 200, 100, 50, 13])\n",
    "deep_model3 = DFN(deep_config3)\n",
    "\n",
    "shallow_config = DFNConfig(architecture=[10])\n",
    "shallow_model = DFN(shallow_config)\n",
    "\n",
    "param_checker(deep_config1, deep_model1)\n",
    "param_checker(deep_config2, deep_model2)\n",
    "param_checker(deep_config3, deep_model3)\n",
    "param_checker(shallow_config, shallow_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos treinar uma rede neural com apenas duas camadas escondidas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfn_config = DFNConfig(architecture=[200, 100, 3])\n",
    "dfn_model = DFN(dfn_config)\n",
    "train_model_img_classification(dfn_model,\n",
    "                               dfn_config,\n",
    "                               self_driving_data,\n",
    "                               'dfn.pkl',\n",
    "                               verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como no caso da regressão logística podemos inspecionar o resultados do treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img, labels = next(iter(self_driving_data.test_loader))\n",
    "\n",
    "dfn_config = DFNConfig(architecture=[200, 100, 3])\n",
    "dfn_model = DFN(dfn_config)\n",
    "\n",
    "\n",
    "dfn_model.load_state_dict(torch.load('dfn.pkl'))\n",
    "img = img / 255\n",
    "pred = dfn_model.predict(img)\n",
    "pred = pred.numpy()\n",
    "\n",
    "plot_confusion_matrix(truth=labels.numpy(),\n",
    "                      predictions=pred,\n",
    "                      save=False,\n",
    "                      path=\"dfn_confusion_matrix.png\",\n",
    "                      classes=[\"forward\", \"left\", \"right\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred9 = pred[0:9]\n",
    "pred9 = [int2command[i] for i in pred9] \n",
    "img9 = img[0:9].numpy()\n",
    "labels9 = labels[0:9].numpy()\n",
    "labels9 = [int2command[i] for i in labels9]\n",
    "img9 = img9.reshape((9, 45, 80, 3))\n",
    "img9 = img9[...,::-1]\n",
    "plot9images(img9, labels9, (45, 80, 3), pred9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora você pode treinar diferentes redes neurais com diferentes arquiteturas e ver qual é a melhor configuração para esse problema."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercício 7: Competição no Kaggle\n",
    "\n",
    "Uma vez treinado o modelo com os dados da pista de treinamento, temos que averiguar se o modelo consegue generalizar bem na pista de teste:\n",
    "\n",
    "<table>\n",
    "<tr>\n",
    "<td>\n",
    "<img align=\"middle\" width='400' heith='100'  src='images/test_track.png'>\n",
    "</td>\n",
    "</tr>\n",
    "</table>\n",
    "\n",
    "As imagens dessa pista estão disponíveis na competição do Kaggle [MAC0460 self driving](https://www.kaggle.com/c/mac0460-self-driving). Há vários dados que não usamos da pasta 'self_driving_pi_car_data', é hora de usar todos eles! Agora você tem que usar todas as funções que você definiu até aqui e tentar treinar um modelo para a competição. Você pode usar outros modelos, outras bibliotecas e manipular os dados do jeito que achar melhor. \n",
    "\n",
    "Nesse último exercício você vai ter que treinar um modelo e submeter para a competição sua predição no formato [csv](https://en.wikipedia.org/wiki/Comma-separated_values). Você vai ter nota completa se você conseguir um valor maior ou igual que $0.65$ (Public Score).\n",
    "\n",
    "A função abaixo ajuda a transformar um array de predições num csv. Boa competição!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def labels2csv(labels, csv_path):\n",
    "    \"\"\"\n",
    "    Transform an array of labels into a csv file\n",
    "    to be submitted on the kaggle competition\n",
    "    https://www.kaggle.com/c/mac0460-self-driving\n",
    "\n",
    "    :param labels: labels\n",
    "    :type labels: np.array\n",
    "    :param csv_path: path to save csv file\n",
    "    :type csv_path: str\n",
    "    \"\"\"\n",
    "    with open(csv_path, \"w\") as file:\n",
    "        file.write(\"id,label\\n\")\n",
    "        for i, label in enumerate(labels):\n",
    "            file.write(\"{},{}\\n\".format(i,label))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
