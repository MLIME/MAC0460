{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objetivos\n",
    "\n",
    "Implementar e testar a soluÃ§Ã£o analÃ­tica para o problema de regressÃ£o linear \n",
    "\n",
    "Este notebook depende de mÃ³dulos auxiliares que estÃ£o na pasta util/ mais alguns imports do Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RegressÃ£o linear: equaÃ§Ãµes normais\n",
    "\n",
    "\n",
    "Dado um dataset $\\{(\\mathbf{x}_{1}, y_{1}), \\dots ,(\\mathbf{x}_{N}, y_{N})\\}$ onde $\\mathbf{x}_i \\in \\mathbb{R}^{d}$ e $y_i \\in \\mathbb{R}$, queremos aproximar a funÃ§Ã£o desconhecida $f:\\mathbb{R}^{d} \\rightarrow \\mathbb{R}$ (lembrando que $y_i =f(\\mathbf{x}_i)$) por meio de um modelo linear $h$:\n",
    "$$\n",
    "h(\\mathbf{x}_{i}; \\mathbf{w}, b) = \\mathbf{w}^\\top  \\mathbf{x}_{i} + b\n",
    "$$\n",
    "\n",
    "Note que $h(\\mathbf{x}_{i}; \\mathbf{w}, b)$ Ã© na verdade uma [transformaÃ§Ã£o afim](https://en.wikipedia.org/wiki/Affine_transformation) de $\\mathbf{x}_{i}$. Como em outros lugares, vamos usar o termo \"linear\" tambÃ©m para caracterizar uma transformaÃ§Ã£o afim.\n",
    "\n",
    "A saÃ­da de $h$ Ã© uma transformaÃ§Ã£o linear de $\\mathbf{x}_{i}$. Usamos a notaÃ§Ã£o $h(\\mathbf{x}_{i}; \\mathbf{w}, b)$ para deixar claro que $h$ Ã© um modelo parametrizado, i.e., a transformaÃ§Ã£o $h$ Ã© definida pelos parÃ¢metros $\\mathbf{w}$ e $b$. Podemos pensar no vetor $\\mathbf{w}$ como um vetor de *pesos* controlando o efeito de cada *feature* na prediÃ§Ã£o.\n",
    "\n",
    "Adicionando uma feature a mais na obsevaÃ§Ã£o $\\mathbf{x}_{i}$ (com o valor 1) -- coordenada artificial -- podemos simplificar a notaÃ§Ã£o do modelo:\n",
    "\n",
    "$$\n",
    "h(\\mathbf{x}_{i}; \\mathbf{w}) = \\hat{y}_{i} = \\mathbf{w}^\\top  \\mathbf{x}_{i}\n",
    "$$\n",
    "\n",
    "GostarÃ­amos de encontrar os melhores parÃ¢metros $\\mathbf{w}$ de modo que a prediÃ§Ã£o $\\hat{y}_{i}$ seja a mais prÃ³xima de $y_{i}$ de acordo com alguma mÃ©trica de erro. Usando o *erro quadrÃ¡rico mÃ©dio* como tal mÃ©trica podemos obter a seguinte funÃ§Ã£o de custo:\n",
    "\n",
    "\\begin{equation}\n",
    "J(\\mathbf{w}) = \\frac{1}{N}\\sum_{i=1}^{N}(\\hat{y}_{i} - y_{i})^{2}\n",
    "\\end{equation}\n",
    "\n",
    "Desse modo, a tarefa de achar a funÃ§Ã£o $h$ mais prÃ³xima de $f$ se torna a tarefa de encontrar os valores de $\\mathbf{w}$ para minimizar $J(\\mathbf{w})$.\n",
    "\n",
    "**Aqui vamos comeÃ§ar a explorar esse modelo olhando para um dataset bem simples**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all imports\n",
    "import numpy as np\n",
    "import time\n",
    "from util.util import get_housing_prices_data, r_squared\n",
    "from util.plots import plot_points_regression \n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### O dataset\n",
    "\n",
    "Os dados que vamos trabalhar sÃ£o dados artificiais. Iremos gerar 100 observaÃ§Ãµes com apenas uma *feature* e um valor asociado a cada uma delas. Podemos interpretar essas observaÃ§Ãµes como sendo um par *(metros quadrados de um imÃ³vel, preÃ§o desse imÃ³vel em $)*. Nossa tarefa Ã© construir um modelo que consiga predizer o valor dos imÃ³veis, dadas as suas Ã¡reas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = get_housing_prices_data(N=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotando os dados\n",
    "\n",
    "Acima temos algumas informaÃ§Ãµes sobre os dados. Podemos tambÃ©m visualizar cada ponto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_points_regression(X,\n",
    "                       y,\n",
    "                       title='Real estate prices prediction',\n",
    "                       xlabel=\"m\\u00b2\",\n",
    "                       ylabel='$')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EquaÃ§Ãµes normais\n",
    "\n",
    "Dados $f:\\mathbb{R}^{n\\times m} \\rightarrow \\mathbb{R}$ e $\\mathbf{A} \\in \\mathbb{R}^{n\\times m}$, definimos o gradiente de $f$ com respeito a $\\mathbf{A}$ como:\n",
    "\n",
    "\\begin{equation*}\n",
    "\\nabla_{\\mathbf{A}}f = \\frac{\\partial f}{\\partial \\mathbf{A}} =  \\begin{bmatrix}\n",
    "\\frac{\\partial f}{\\partial \\mathbf{A}_{1,1}} & \\dots & \\frac{\\partial f}{\\partial \\mathbf{A}_{1,m}} \\\\\n",
    "\\vdots &  \\ddots & \\vdots \\\\\n",
    "\\frac{\\partial f}{\\partial \\mathbf{A}_{n,1}} &  \\dots & \\frac{\\partial f}{\\partial \\mathbf{A}_{n,m}}\n",
    "\\end{bmatrix}\n",
    "\\end{equation*}\n",
    "\n",
    "Seja $\\mathbf{X} \\in \\mathbb{R}^{N\\times m}$ a matriz cujas linhas sÃ£o as observaÃ§Ãµes do dataset (tambÃ©m chamada de *design matrix*) e seja $\\mathbf{y} \\in \\mathbb{R}^{N}$ o vetor contendo todos os valores de $y_{i}$ (i.e., $\\mathbf{X}_{i,:} = \\mathbf{x}_{i}$ e $\\mathbf{y}_{i} =y_{i}$). Ã‰ fÃ¡cil checar que: \n",
    "\n",
    "\n",
    "\\begin{equation}\n",
    "J(\\mathbf{w}) = \\frac{1}{N}(\\mathbf{X}\\mathbf{w} - \\mathbf{y})^{T}(\\mathbf{X}\\mathbf{w} - \\mathbf{y})\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "Usando certos conceitos bÃ¡sicos de derivada com matrizes podemos chegar no gradiente de $J(\\mathbf{w})$ com respeito a $\\mathbf{w}$:\n",
    "\n",
    "\\begin{equation}\n",
    "\\nabla_{\\mathbf{w}}J(\\mathbf{w}) = \\frac{2}{N} (\\mathbf{X}^{T}\\mathbf{X}\\mathbf{w} -\\mathbf{X}^{T}\\mathbf{y})   \n",
    "\\end{equation}\n",
    "\n",
    "Assim, quando $\\nabla_{\\mathbf{w}}J(\\mathbf{w}) = 0$ temos que \n",
    "\n",
    "\\begin{equation}\n",
    "\\mathbf{X}^{T}\\mathbf{X}\\mathbf{w} = \\mathbf{X}^{T}\\mathbf{y}\n",
    "\\end{equation}\n",
    "\n",
    "Desse modo,\n",
    "\n",
    "\\begin{equation}\n",
    "\\mathbf{w} = (\\mathbf{X}^{T}\\mathbf{X})^{-1}\\mathbf{X}^{T}\\mathbf{y}\n",
    "\\end{equation}\n",
    "\n",
    "A soluÃ§Ã£o dada por essas equaÃ§Ãµes sÃ£o conhecidas como **equaÃ§Ãµes normais**. Note que esse tipo de soluÃ§Ã£o tem um custo, pois conforme cresce o nÃºmero de variÃ¡veis, o tempo da inversÃ£o da matriz fica proibitivo. Vale a pena ler [esse material](http://cs229.stanford.edu/notes/cs229-notes1.pdf) para ver o argumento com mais detalhes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ExercÃ­cio\n",
    "Usando apenas a biblioteca **NumPy** (uma introduÃ§Ã£o rÃ¡pida a certas funcionalidades dessa biblioteca pode ser encontrada [aqui](http://cs231n.github.io/python-numpy-tutorial/)), complete as duas funÃ§Ãµes abaixo. Lembre que $\\mathbf{X} \\in \\mathbb{R}^{N\\times d}$; assim, serÃ¡ preciso adicionar uma componente com valor 1 a cada observaÃ§Ã£o em $\\mathbf{X}$ para realizar a computaÃ§Ã£o descrita acima."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normal_equation_weights(X, y):\n",
    "    \"\"\"\n",
    "    Calculates the weights of a linear function using the normal equation method.\n",
    "    You should add into X a new column with 1s.\n",
    "\n",
    "    :param X: design matrix\n",
    "    :type X: np.ndarray(shape=(N, d))\n",
    "    :param y: regression targets\n",
    "    :type y: np.ndarray(shape=(N, 1))\n",
    "    :return: weight vector\n",
    "    :rtype: np.ndarray(shape=(d+1, 1))\n",
    "    \"\"\"\n",
    "    \n",
    "    # START OF YOUR CODE:\n",
    "    raise NotImplementedError(\"Falta implementar normal_equation_weights()\")\n",
    "    # END YOUR CODE\n",
    "\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# teste da funÃ§Ã£o normal_equation_weights()\n",
    "\n",
    "w = 0  # isto Ã© desnecessÃ¡rio\n",
    "w = normal_equation_weights(X, y)\n",
    "print(\"Estimated w = \", w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normal_equation_prediction(X, w):\n",
    "    \"\"\"\n",
    "    Calculates the prediction over a set of observations X using the linear function\n",
    "    characterized by the weight vector w.\n",
    "    You should add into X a new column with 1s.\n",
    "\n",
    "    :param X: design matrix\n",
    "    :type X: np.ndarray(shape=(N, d))\n",
    "    :param w: weight vector\n",
    "    :type w: np.ndarray(shape=(d+1, 1))\n",
    "    :param y: regression prediction\n",
    "    :type y: np.ndarray(shape=(N, 1))\n",
    "    \"\"\"\n",
    "    \n",
    "    # START OF YOUR CODE:\n",
    "    raise NotImplementedError(\"Falta implementar normal_equation_prediction()\")\n",
    "    # END YOUR CODE\n",
    "    \n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "VocÃª pode usar a mÃ©trica [$R^2$](https://pt.wikipedia.org/wiki/R%C2%B2) para ver o quÃ£o bem o modelo linear estÃ¡ se ajustando aos dados.\n",
    "\n",
    "**Nesse caso $ð‘…^2$ tem que estar prÃ³ximo de 0.5.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# teste da funÃ§Ã£o normal_equation_prediction()\n",
    "prediction = normal_equation_prediction(X, w)\n",
    "r_2 = r_squared(y, prediction)\n",
    "plot_points_regression(X,\n",
    "                       y,\n",
    "                       title='Real estate prices prediction',\n",
    "                       xlabel=\"m\\u00b2\",\n",
    "                       ylabel='$',\n",
    "                       prediction=prediction,\n",
    "                       legend=True,\n",
    "                       r_squared=r_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testes adicionais\n",
    "\n",
    "Vamos fazer a prediÃ§Ã£o para $x=650$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# usando a funÃ§Ã£o de prediÃ§Ã£o\n",
    "x = np.asarray([650]).reshape(1,1)\n",
    "prediction = normal_equation_prediction(x, w)\n",
    "print(\"Area = %.2f  Predicted price = %.4f\" %(x[0], prediction))\n",
    "\n",
    "# de forma mais direta\n",
    "y = np.dot(np.asarray((1,x)), w)\n",
    "print(\"Area = %.2f  Predicted price = %.4f\" %(x, y))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Efeito do nÃºmero de amostras e dimensÃ£o dos dados\n",
    "\n",
    "Varie o nÃºmero de amostras $N$ e veja como varia o tempo de processamento.\n",
    "\n",
    "Teste o seu cÃ³digo para dados nos quais $ð‘‘>1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Teste para diferentes valores de N\n",
    "X, y = get_housing_prices_data(N=1000000)\n",
    "init = time.time()\n",
    "w = normal_equation_weights(X, y)\n",
    "prediction = normal_equation_prediction(X,w)\n",
    "init = time.time() - init\n",
    "\n",
    "print(\"Tempo de execuÃ§Ã£o = {:.8f}(s)\".format(init))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Teste para dados de dimensÃ£o d>1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
